{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "raw",
      "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/Diffutoon-jupyter/blob/main/Diffutoon_color_jupyter.ipynb)",
      "metadata": {
        "id": "view-in-github"
      }
    },
    {
      "cell_type": "code",
      "source": "# https://github.com/modelscope/DiffSynth-Studio/blob/main/examples/Diffutoon/Diffutoon.ipynb modified\n\n%cd /content\n!git clone https://github.com/Artiprocher/DiffSynth-Studio\n%cd /content/DiffSynth-Studio\n\n!pip install -q einops transformers controlnet-aux==0.0.7 sentencepiece imageio imageio-ffmpeg\n\n!apt -y install -qq aria2\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/229575 -d /content/DiffSynth-Studio/models/stable_diffusion -o aingdiffusion_v12.safetensors\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15_v2.ckpt -d /content/DiffSynth-Studio/models/AnimateDiff -o mm_sd_v15_v2.ckpt\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart.pth -d /content/DiffSynth-Studio/models/ControlNet -o control_v11p_sd15_lineart.pth\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth -d /content/DiffSynth-Studio/models/ControlNet -o control_v11f1e_sd15_tile.pth\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth -d /content/DiffSynth-Studio/models/ControlNet -o control_v11f1p_sd15_depth.pth\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge.pth -d /content/DiffSynth-Studio/models/ControlNet -o control_v11p_sd15_softedge.pth\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/Annotators/resolve/main/dpt_hybrid-midas-501f0c75.pt -d /content/DiffSynth-Studio/models/Annotators -o dpt_hybrid-midas-501f0c75.pt\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/Annotators/resolve/main/ControlNetHED.pth -d /content/DiffSynth-Studio/models/Annotators -o ControlNetHED.pth\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/Annotators/resolve/main/sk_model.pth -d /content/DiffSynth-Studio/models/Annotators -o sk_model.pth\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/lllyasviel/Annotators/resolve/main/sk_model2.pth -d /content/DiffSynth-Studio/models/Annotators -o sk_model2.pth\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"https://civitai.com/api/download/models/25820?type=Model&format=PickleTensor&size=full&fp=fp16\" -d /content/DiffSynth-Studio/models/textual_inversion -o verybadimagenegative_v1.3.pt\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/Diffutoon/resolve/main/input_video.mp4 -d /content -o input_video.mp4",
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from google.colab import drive\ndrive.mount('/content/drive')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import shutil\nimport os\n\n# 定义源文件路径和目标文件路径\nsource_file = '/content/drive/MyDrive/test_auto_mv/input_video333.mp4'\ndestination_dir = '/content'\ndestination_file = os.path.join(destination_dir, 'input_video.mp4')\n\n# 确保目标目录存在，如果不存在则创建\nif not os.path.exists(destination_dir):\n    os.makedirs(destination_dir)\n\n# 移动并重命名文件\nshutil.move(source_file, destination_file)\n\nprint(f'File moved to {destination_file}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "config_stage_1_template = {\n    \"models\": {\n        \"model_list\": [\n            \"models/stable_diffusion/aingdiffusion_v12.safetensors\",\n            \"models/ControlNet/control_v11p_sd15_softedge.pth\",\n            \"models/ControlNet/control_v11f1p_sd15_depth.pth\"\n        ],\n        \"textual_inversion_folder\": \"models/textual_inversion\",\n        \"device\": \"cuda\",\n        \"lora_alphas\": [],\n        \"controlnet_units\": [\n            {\n                \"processor_id\": \"softedge\",\n                \"model_path\": \"models/ControlNet/control_v11p_sd15_softedge.pth\",\n                \"scale\": 0.5\n            },\n            {\n                \"processor_id\": \"depth\",\n                \"model_path\": \"models/ControlNet/control_v11f1p_sd15_depth.pth\",\n                \"scale\": 0.5\n            }\n        ]\n    },\n    \"data\": {\n        \"input_frames\": {\n            \"video_file\": \"/content/input_video.mp4\",\n            \"image_folder\": None,\n            \"height\": 720,\n            \"width\": 480,\n            \"start_frame_id\": 0,\n            \"end_frame_id\": 30\n        },\n        \"controlnet_frames\": [\n            {\n                \"video_file\": \"/content/input_video.mp4\",\n                \"image_folder\": None,\n                \"height\": 720,\n                \"width\": 480,\n                \"start_frame_id\": 0,\n                \"end_frame_id\": 30\n            },\n            {\n                \"video_file\": \"/content/input_video.mp4\",\n                \"image_folder\": None,\n                \"height\": 720,\n                \"width\": 480,\n                \"start_frame_id\": 0,\n                \"end_frame_id\": 30\n            }\n        ],\n        \"output_folder\": \"data/examples/diffutoon_edit/color_video\",\n        \"fps\": 25\n    },\n    \"smoother_configs\": [\n        {\n            \"processor_type\": \"FastBlend\",\n            \"config\": {}\n        }\n    ],\n    \"pipeline\": {\n        \"seed\": 0,\n        \"pipeline_inputs\": {\n            \"prompt\": \"best quality, perfect anime illustration, orange clothes, night, a girl is dancing, smile, solo, black silk stockings\",\n            \"negative_prompt\": \"verybadimagenegative_v1.3\",\n            \"cfg_scale\": 7.0,\n            \"clip_skip\": 1,\n            \"denoising_strength\": 0.9,\n            \"num_inference_steps\": 20,\n            \"animatediff_batch_size\": 8,\n            \"animatediff_stride\": 4,\n            \"unet_batch_size\": 8,\n            \"controlnet_batch_size\": 8,\n            \"cross_frame_attention\": True,\n            \"smoother_progress_ids\": [-1],\n            # The following parameters will be overwritten. You don't need to modify them.\n            \"input_frames\": [],\n            \"num_frames\": 30,\n            \"width\": 480,\n            \"height\": 720,\n            \"controlnet_frames\": []\n        }\n    }\n}\n\nfrom diffsynth import SDVideoPipelineRunner\n\nconfig_stage_1 = config_stage_1_template.copy()\nconfig_stage_1[\"data\"][\"input_frames\"] = {\n    \"video_file\": \"/content/input_video.mp4\",\n    \"image_folder\": None,\n    \"height\": 720,\n    \"width\": 480,\n    \"start_frame_id\": 0,\n    \"end_frame_id\": 30\n}\nconfig_stage_1[\"data\"][\"controlnet_frames\"] = [config_stage_1[\"data\"][\"input_frames\"], config_stage_1[\"data\"][\"input_frames\"]]\nconfig_stage_1[\"data\"][\"output_folder\"] = \"/content/color_video\"\nconfig_stage_1[\"data\"][\"fps\"] = 25\nconfig_stage_1[\"pipeline\"][\"pipeline_inputs\"][\"prompt\"] = \"best quality, perfect anime illustration, orange clothes, night, a girl is dancing, smile, solo, black silk stockings\"\n\nrunner = SDVideoPipelineRunner()\nrunner.run(config_stage_1)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import shutil\nimport os\n\n# 定义源文件路径和目标文件路径\nsource_file = '/content/color_video/video.mp4'\ndestination_dir = '/content/drive/MyDrive/test_auto_mv'\ndestination_file = os.path.join(destination_dir, 'video1.mp4')\n\n# 确保目标目录存在，如果不存在则创建\nif not os.path.exists(destination_dir):\n    os.makedirs(destination_dir)\n\n# 移动并重命名文件\nshutil.move(source_file, destination_file)\n\nprint(f'File moved to {destination_file}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "config_stage_1_template = {\n    \"models\": {\n        \"model_list\": [\n            \"models/stable_diffusion/aingdiffusion_v12.safetensors\",\n            \"models/ControlNet/control_v11p_sd15_softedge.pth\",\n            \"models/ControlNet/control_v11f1p_sd15_depth.pth\"\n        ],\n        \"textual_inversion_folder\": \"models/textual_inversion\",\n        \"device\": \"cuda\",\n        \"lora_alphas\": [],\n        \"controlnet_units\": [\n            {\n                \"processor_id\": \"softedge\",\n                \"model_path\": \"models/ControlNet/control_v11p_sd15_softedge.pth\",\n                \"scale\": 0.5\n            },\n            {\n                \"processor_id\": \"depth\",\n                \"model_path\": \"models/ControlNet/control_v11f1p_sd15_depth.pth\",\n                \"scale\": 0.5\n            }\n        ]\n    },\n    \"data\": {\n        \"input_frames\": {\n            \"video_file\": \"/content/input_video.mp4\",\n            \"image_folder\": None,\n            \"height\": 720,\n            \"width\": 480,\n            \"start_frame_id\": 31,\n            \"end_frame_id\": 61\n        },\n        \"controlnet_frames\": [\n            {\n                \"video_file\": \"/content/input_video.mp4\",\n                \"image_folder\": None,\n                \"height\": 720,\n                \"width\": 480,\n                \"start_frame_id\": 31,\n                \"end_frame_id\": 61\n            },\n            {\n                \"video_file\": \"/content/input_video.mp4\",\n                \"image_folder\": None,\n                \"height\": 720,\n                \"width\": 480,\n                \"start_frame_id\": 31,\n                \"end_frame_id\": 61\n            }\n        ],\n        \"output_folder\": \"data/examples/diffutoon_edit/color_video\",\n        \"fps\": 25\n    },\n    \"smoother_configs\": [\n        {\n            \"processor_type\": \"FastBlend\",\n            \"config\": {}\n        }\n    ],\n    \"pipeline\": {\n        \"seed\": 0,\n        \"pipeline_inputs\": {\n            \"prompt\": \"best quality, perfect anime illustration, orange clothes, night, a girl is dancing, smile, solo, black silk stockings\",\n            \"negative_prompt\": \"verybadimagenegative_v1.3\",\n            \"cfg_scale\": 7.0,\n            \"clip_skip\": 1,\n            \"denoising_strength\": 0.9,\n            \"num_inference_steps\": 20,\n            \"animatediff_batch_size\": 8,\n            \"animatediff_stride\": 4,\n            \"unet_batch_size\": 8,\n            \"controlnet_batch_size\": 8,\n            \"cross_frame_attention\": True,\n            \"smoother_progress_ids\": [-1],\n            # The following parameters will be overwritten. You don't need to modify them.\n            \"input_frames\": [],\n            \"num_frames\": 30,\n            \"width\": 480,\n            \"height\": 720,\n            \"controlnet_frames\": []\n        }\n    }\n}\n\nfrom diffsynth import SDVideoPipelineRunner\n\nconfig_stage_1 = config_stage_1_template.copy()\nconfig_stage_1[\"data\"][\"input_frames\"] = {\n    \"video_file\": \"/content/input_video.mp4\",\n    \"image_folder\": None,\n    \"height\": 720,\n    \"width\": 480,\n    \"start_frame_id\": 31,\n    \"end_frame_id\": 61\n}\nconfig_stage_1[\"data\"][\"controlnet_frames\"] = [config_stage_1[\"data\"][\"input_frames\"], config_stage_1[\"data\"][\"input_frames\"]]\nconfig_stage_1[\"data\"][\"output_folder\"] = \"/content/color_video\"\nconfig_stage_1[\"data\"][\"fps\"] = 25\nconfig_stage_1[\"pipeline\"][\"pipeline_inputs\"][\"prompt\"] = \"best quality, perfect anime illustration, orange clothes, night, a girl is dancing, smile, solo, black silk stockings\"\n\nrunner = SDVideoPipelineRunner()\nrunner.run(config_stage_1)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "raw",
      "source": "import shutil\nimport os\n\n# 定义源文件路径和目标文件路径\nsource_file = '/content/color_video/video.mp4'\ndestination_dir = '/content/drive/MyDrive/test_auto_mv'\ndestination_file = os.path.join(destination_dir, 'video2.mp4')\n\n# 确保目标目录存在，如果不存在则创建\nif not os.path.exists(destination_dir):\n    os.makedirs(destination_dir)\n\n# 移动并重命名文件\nshutil.move(source_file, destination_file)\n\nprint(f'File moved to {destination_file}')",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import shutil\nimport os\n\n# 定义源文件路径和目标文件路径\nsource_file = '/content/color_video/video.mp4'\ndestination_dir = '/content/drive/MyDrive/test_auto_mv'\ndestination_file = os.path.join(destination_dir, 'video1.mp4')\n\n# 确保目标目录存在，如果不存在则创建\nif not os.path.exists(destination_dir):\n    os.makedirs(destination_dir)\n\n# 移动并重命名文件\nshutil.move(source_file, destination_file)\n\nprint(f'File moved to {destination_file}')",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "config_stage_2_template = {\n    \"models\": {\n        \"model_list\": [\n            \"models/stable_diffusion/aingdiffusion_v12.safetensors\",\n            \"models/AnimateDiff/mm_sd_v15_v2.ckpt\",\n            \"models/ControlNet/control_v11f1e_sd15_tile.pth\",\n            \"models/ControlNet/control_v11p_sd15_lineart.pth\"\n        ],\n        \"textual_inversion_folder\": \"models/textual_inversion\",\n        \"device\": \"cuda\",\n        \"lora_alphas\": [],\n        \"controlnet_units\": [\n            {\n                \"processor_id\": \"tile\",\n                \"model_path\": \"models/ControlNet/control_v11f1e_sd15_tile.pth\",\n                \"scale\": 0.5\n            },\n            {\n                \"processor_id\": \"lineart\",\n                \"model_path\": \"models/ControlNet/control_v11p_sd15_lineart.pth\",\n                \"scale\": 0.5\n            }\n        ]\n    },\n    \"data\": {\n        \"input_frames\": {\n            \"video_file\": \"/content/input_video.mp4\",\n            \"image_folder\": None,\n            \"height\": 1024,\n            \"width\": 1024,\n            \"start_frame_id\": 0,\n            \"end_frame_id\": 30\n        },\n        \"controlnet_frames\": [\n            {\n                \"video_file\": \"/content/input_video.mp4\",\n                \"image_folder\": None,\n                \"height\": 1024,\n                \"width\": 1024,\n                \"start_frame_id\": 0,\n                \"end_frame_id\": 30\n            },\n            {\n                \"video_file\": \"/content/input_video.mp4\",\n                \"image_folder\": None,\n                \"height\": 1024,\n                \"width\": 1024,\n                \"start_frame_id\": 0,\n                \"end_frame_id\": 30\n            }\n        ],\n        \"output_folder\": \"/content/output\",\n        \"fps\": 25\n    },\n    \"pipeline\": {\n        \"seed\": 0,\n        \"pipeline_inputs\": {\n            \"prompt\": \"best quality, perfect anime illustration, light, a girl is dancing, smile, solo\",\n            \"negative_prompt\": \"verybadimagenegative_v1.3\",\n            \"cfg_scale\": 7.0,\n            \"clip_skip\": 2,\n            \"denoising_strength\": 1.0,\n            \"num_inference_steps\": 10,\n            \"animatediff_batch_size\": 16,\n            \"animatediff_stride\": 8,\n            \"unet_batch_size\": 1,\n            \"controlnet_batch_size\": 1,\n            \"cross_frame_attention\": False,\n            # The following parameters will be overwritten. You don't need to modify them.\n            \"input_frames\": [],\n            \"num_frames\": 30,\n            \"width\": 1536,\n            \"height\": 1536,\n            \"controlnet_frames\": []\n        }\n    }\n}\n\nfrom diffsynth import SDVideoPipelineRunner\n\nconfig_stage_2 = config_stage_2_template.copy()\nconfig_stage_2[\"data\"][\"input_frames\"] = {\n    \"video_file\": \"/content/input_video.mp4\",\n    \"image_folder\": None,\n    \"height\": 1024,\n    \"width\": 1024,\n    \"start_frame_id\": 0,\n    \"end_frame_id\": 30\n}\nconfig_stage_2[\"data\"][\"controlnet_frames\"][0] = {\n    \"video_file\": \"/content/color_video/video.mp4\",\n    \"image_folder\": None,\n    \"height\": config_stage_2[\"data\"][\"input_frames\"][\"height\"],\n    \"width\": config_stage_2[\"data\"][\"input_frames\"][\"width\"],\n    \"start_frame_id\": None,\n    \"end_frame_id\": None\n}\nconfig_stage_2[\"data\"][\"controlnet_frames\"][1] = config_stage_2[\"data\"][\"input_frames\"]\nconfig_stage_2[\"data\"][\"output_folder\"] = \"/content/edit_video\"\nconfig_stage_2[\"data\"][\"fps\"] = 25\n\nrunner = SDVideoPipelineRunner()\nrunner.run(config_stage_2)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import moviepy.editor\nmoviepy.editor.ipython_display(\"/content/edit_video/video.mp4\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}
